{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/KOSA-GPT_Python-2023/blob/main/PDF-gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF 파일기반 질의응답 챗봇 (랭체인, 그라디오, ChatGPT)"
      ],
      "metadata": {
        "id": "u-KIIvQ5NKJP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHgrhVbLnM6I"
      },
      "outputs": [],
      "source": [
        "# !pip install openai # openai 라이브러리를 설치합니다.\n",
        "# !pip install langchain # 랭체인 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" # 환경변수에 OPENAI_API_KEY를 설정합니다."
      ],
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "gveJwPgiVRMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pypdf\n",
        "# !pip install chromadb\n",
        "# !pip install tiktoken"
      ],
      "metadata": {
        "id": "lSX_ndLWHJqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 새 섹션"
      ],
      "metadata": {
        "id": "4UexYxjb33sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.embeddings.cohere import CohereEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores.elastic_vector_search import ElasticVectorSearch\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "5kZxXmSjQRHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"foundation-model.pdf\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "Jcft7CmL-xme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "7VgBZ49vQVzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts"
      ],
      "metadata": {
        "id": "6hUyQu5tTdoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "vector_store = Chroma.from_documents(texts, embeddings)\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "4otdIuNkT5b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Modify model_name if you have access to GPT-4\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"map_reduce\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True)"
      ],
      "metadata": {
        "id": "gY8Mtw-OamW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the foundation model?\"\n",
        "result = chain(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "xDW1hZX3a_1w",
        "outputId": "35c38a74-1ee7-4500-b85d-44d6696a0956",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What is the foundation model?', 'answer': 'The foundation model is a type of AI model that is trained on broad data using self-supervision at scale and can be adapted to a wide range of downstream tasks. It is characterized by its central yet incomplete nature and has achieved impressive achievements in AI, demonstrating remarkable performance, interpretability, robustness, controllability, and generalization. The five essential properties of a foundation model are expressivity, scalability, multimodality, memory capacity, and compositionality.\\n', 'sources': 'foundation-model.pdf', 'source_documents': [Document(page_content='On the Opportunities and Risks of\\nFoundation Models\\nRishi Bommasani* Drew A. Hudson Ehsan Adeli Russ Altman Simran Arora\\nSydney von Arx Michael S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill\\nErik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji\\nAnnie Chen Kathleen Creel Jared Quincy Davis Dorottya Demszky Chris Donahue\\nMoussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh\\nLi Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman\\nShelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt\\nDaniel E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain\\nDan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani\\nOmar Khattab Pang Wei Koh Mark Krass Ranjay Krishna Rohith Kuditipudi\\nAnanya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent\\nXiang Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher D. Manning\\nSuvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan\\nDeepak Narayanan Ben Newman Allen Nie Juan Carlos Niebles Hamed Nilforoshan\\nJulian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon Sung Park Chris Piech\\nEva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren\\nFrieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh\\nShiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin\\nRohan Taori Armin W. Thomas Florian Tramèr Rose E. Wang William Wang Bohan Wu\\nJiajun Wu Yuhuai Wu Sang Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia\\nMichael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou\\nPercy Liang*1\\nCenter for Research on Foundation Models (CRFM)\\nStanford Institute for Human-Centered Artificial Intelligence (HAI)\\nStanford University\\nAI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) trained on broad\\ndata (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks.\\nWe call these models foundation models to underscore their critically central yet incomplete character.\\nThis report provides a thorough account of the opportunities and risks of foundation models, ranging\\nfrom their capabilities (e.g., language, vision, robotic manipulation, reasoning, human interaction) and\\ntechnical principles (e.g., model architectures, training procedures, data, systems, security, evaluation,\\ntheory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse,\\neconomic and environmental impact, legal and ethical considerations). Though foundation models are\\nbased on standard deep learning and transfer learning, their scale results in new emergent capabilities,\\nand their effectiveness across so many tasks incentivizes homogenization. Homogenization provides\\npowerful leverage but demands caution, as the defects of the foundation model are inherited by all the\\nadapted models downstream. Despite the impending widespread deployment of foundation models,\\nwe currently lack a clear understanding of how they work, when they fail, and what they are even\\ncapable of due to their emergent properties. To tackle these questions, we believe much of the critical\\nresearch on foundation models will require deep interdisciplinary collaboration commensurate with\\ntheir fundamentally sociotechnical nature.\\n1Corresponding author: pliang@cs.stanford.edu *Equal contribution.\\n1arXiv:2108.07258v3  [cs.LG]  12 Jul 2022', metadata={'source': 'foundation-model.pdf', 'page': 0}), Document(page_content='74 Center for Research on Foundation Models (CRFM)\\n4.1 Modeling\\nAuthors: Drew A. Hudson, Antoine Bosselut, Alex Tamkin, Omar Khattab, Jared Quincy Davis, Jiaxuan\\nYou, Trevor Gale\\nFig. 17. The five key properties of a foundation model: expressivity — to flexibly capture and represent rich\\ninformation; scalability — to efficiently consume large quantities of data; multimodality — to connect together\\nvarious modalities and domains; memory capacity — to store the vast amount of accumulated knowledge;\\nandcompositionality — to generalize to new contexts, tasks and environments.\\nThe emerging paradigm of foundation models has attained impressive achievements in AI over\\nthe last few years, as models such as BERT [Devlin et al .2019] shine at a wide spectrum of language\\nunderstanding tasks: from textual classification and entailment to question answering and reading\\ncomprehension, while GPT-3 composes rich and fluent tales about unicorns [Brown et al .2020]\\nand DALL-E shows signs of visual creativity, generating from scratch strikingly-realistic pictures\\nof avocado chairs [Ramesh et al. 2021].\\nThese and other instances of recent foundation models not only achieve remarkable performance\\nacross a multitude of diverse downstream tasks and applications [Rajpurkar et al .2018; Wang et al .\\n2019a], but also manifest noteworthy behaviors of interpretability [Karras et al .2020], robustness\\n[Devlin et al .2019], controllability [Patashnik et al .2021] and generalization [Brown et al .2020].\\nWhat does it take for a model to demonstrate such qualities? What architectures are capable of\\nconsuming large quantities of potentially multimodal information and translate them into rich\\nknowledge of the world? And overall, what desirable properties should a network possess to give\\nrise to a foundation model?\\nHere, we identify and discuss five such properties, spanning expressivity ,scalability ,multimodality ,\\nmemory capacity , and compositionality , that we believe are essential for a foundation model in\\norder to: (1) distill and accumulate knowledge from various sources and domains, (2) organize it in\\nan effective and scalable representation, and (3) flexibly generalize it towards novel contexts. For\\neach of these properties, we motivate their necessity, provide examples of contemporary models\\nthat incorporate them, and explore key challenges and promising avenues for future research and\\ndevelopment. See Figure 17 for an overview diagram.', metadata={'source': 'foundation-model.pdf', 'page': 73})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "id": "LecxXSyoAN1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "Qr0_iNsLTb6y",
        "outputId": "5c105b48-e6af-4093-9346-7b7d7fd2bbbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The foundation model is a type of AI model that is trained on broad data using self-supervision at scale and can be adapted to a wide range of downstream tasks. It is characterized by its central yet incomplete nature and has achieved impressive achievements in AI, demonstrating remarkable performance, interpretability, robustness, controllability, and generalization. The five essential properties of a foundation model are expressivity, scalability, multimodality, memory capacity, and compositionality.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['sources']"
      ],
      "metadata": {
        "id": "Yjs65WFeTivP",
        "outputId": "b06d140f-9b23-4d97-9eb7-cffe99a4b616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'foundation-model.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "system_template=\"\"\"Use the following pieces of context to answer the users question shortly.\n",
        "Given the following summaries of a long document and a question, create a final answer with references (\"SOURCES\"), use \"SOURCES\" in capital letters regardless of the number of sources.\n",
        "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
        "----------------\n",
        "{summaries}\n",
        "\n",
        "You MUST answer in Korean and in Markdown format:\"\"\"\n",
        "\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(messages)"
      ],
      "metadata": {
        "id": "InBq74JFacah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "\n",
        "chain_type_kwargs = {\"prompt\": prompt}\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)  # Modify model_name if you have access to GPT-4\n",
        "\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever = retriever,\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs=chain_type_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "GfUMi5ClS_4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the proposal of foundation model?\"\n",
        "result = chain(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "pVdJrxN0TzwC",
        "outputId": "50e8be55-1fbb-453e-fbd9-5b9a50272df7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'What is the proposal of foundation model?', 'answer': '기초 모델의 제안은 다양한 하위 작업에 적용할 수 있는 광범위한 데이터로 훈련된 모델을 개발하는 것입니다. 이러한 모델은 BERT, DALL-E, GPT-3 등으로 알려진 모델들을 포함하며, 언어, 비전, 로봇 조작, 추론, 인간 상호작용 등 다양한 능력을 갖추고 있습니다. 이 보고서는 기초 모델의 기회와 위험에 대해 상세히 설명하고 있으며, 모델의 능력, 기술 원칙, 응용 분야, 사회적 영향 등을 다루고 있습니다. 또한, 기초 모델의 결함이 하위 작업에 적용된 모든 모델에 상속된다는 주의가 필요하다고 언급하고 있습니다. 이러한 질문들에 대한 명확한 이해와 연구를 위해 깊은 학문적 협력이 필요하다고 강조하고 있습니다. (', 'sources': 'foundation-model.pdf)', 'source_documents': [Document(page_content='On the Opportunities and Risks of\\nFoundation Models\\nRishi Bommasani* Drew A. Hudson Ehsan Adeli Russ Altman Simran Arora\\nSydney von Arx Michael S. Bernstein Jeannette Bohg Antoine Bosselut Emma Brunskill\\nErik Brynjolfsson Shyamal Buch Dallas Card Rodrigo Castellon Niladri Chatterji\\nAnnie Chen Kathleen Creel Jared Quincy Davis Dorottya Demszky Chris Donahue\\nMoussa Doumbouya Esin Durmus Stefano Ermon John Etchemendy Kawin Ethayarajh\\nLi Fei-Fei Chelsea Finn Trevor Gale Lauren Gillespie Karan Goel Noah Goodman\\nShelby Grossman Neel Guha Tatsunori Hashimoto Peter Henderson John Hewitt\\nDaniel E. Ho Jenny Hong Kyle Hsu Jing Huang Thomas Icard Saahil Jain\\nDan Jurafsky Pratyusha Kalluri Siddharth Karamcheti Geoff Keeling Fereshte Khani\\nOmar Khattab Pang Wei Koh Mark Krass Ranjay Krishna Rohith Kuditipudi\\nAnanya Kumar Faisal Ladhak Mina Lee Tony Lee Jure Leskovec Isabelle Levent\\nXiang Lisa Li Xuechen Li Tengyu Ma Ali Malik Christopher D. Manning\\nSuvir Mirchandani Eric Mitchell Zanele Munyikwa Suraj Nair Avanika Narayan\\nDeepak Narayanan Ben Newman Allen Nie Juan Carlos Niebles Hamed Nilforoshan\\nJulian Nyarko Giray Ogut Laurel Orr Isabel Papadimitriou Joon Sung Park Chris Piech\\nEva Portelance Christopher Potts Aditi Raghunathan Rob Reich Hongyu Ren\\nFrieda Rong Yusuf Roohani Camilo Ruiz Jack Ryan Christopher Ré Dorsa Sadigh\\nShiori Sagawa Keshav Santhanam Andy Shih Krishnan Srinivasan Alex Tamkin\\nRohan Taori Armin W. Thomas Florian Tramèr Rose E. Wang William Wang Bohan Wu\\nJiajun Wu Yuhuai Wu Sang Michael Xie Michihiro Yasunaga Jiaxuan You Matei Zaharia\\nMichael Zhang Tianyi Zhang Xikun Zhang Yuhui Zhang Lucia Zheng Kaitlyn Zhou\\nPercy Liang*1\\nCenter for Research on Foundation Models (CRFM)\\nStanford Institute for Human-Centered Artificial Intelligence (HAI)\\nStanford University\\nAI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) trained on broad\\ndata (generally using self-supervision at scale) that can be adapted to a wide range of downstream tasks.\\nWe call these models foundation models to underscore their critically central yet incomplete character.\\nThis report provides a thorough account of the opportunities and risks of foundation models, ranging\\nfrom their capabilities (e.g., language, vision, robotic manipulation, reasoning, human interaction) and\\ntechnical principles (e.g., model architectures, training procedures, data, systems, security, evaluation,\\ntheory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse,\\neconomic and environmental impact, legal and ethical considerations). Though foundation models are\\nbased on standard deep learning and transfer learning, their scale results in new emergent capabilities,\\nand their effectiveness across so many tasks incentivizes homogenization. Homogenization provides\\npowerful leverage but demands caution, as the defects of the foundation model are inherited by all the\\nadapted models downstream. Despite the impending widespread deployment of foundation models,\\nwe currently lack a clear understanding of how they work, when they fail, and what they are even\\ncapable of due to their emergent properties. To tackle these questions, we believe much of the critical\\nresearch on foundation models will require deep interdisciplinary collaboration commensurate with\\ntheir fundamentally sociotechnical nature.\\n1Corresponding author: pliang@cs.stanford.edu *Equal contribution.\\n1arXiv:2108.07258v3  [cs.LG]  12 Jul 2022', metadata={'source': 'foundation-model.pdf', 'page': 0}), Document(page_content='12 Center for Research on Foundation Models (CRFM)\\nAnother complementary approach is to rely on volunteer computing, in which any of the\\nbillions of computing devices (nodes) can connect to a central server and contribute computation.\\nThe Folding@home project has successfully implemented this approach for simulating protein\\ndynamics [Beberg et al .2009]. Recently, the Learning@home project is attempting to harness\\nvolunteer computing for training foundation models [Ryabinin and Gusev 2020]. The high latency\\nconnections between nodes and the high bandwidth requirements for training foundation models\\nmake this an open technical challenge.\\nSummary. There are tremendous economic incentives to push the capabilities and scale of foun-\\ndation models, so we anticipate steady technological progress over the coming years. But the\\nsuitability of a technology relying largely on emergent behavior for widespread deployment to\\npeople is unclear. What is clear that we need to be cautious, and that now is the time to establish\\nthe professional norms that will enable the responsible research and deployment of foundation\\nmodels. Academia and industry need to collaborate on this: industry ultimately makes concrete\\ndecisions about how foundation models will be deployed, but we should also lean on academia,\\nwith its disciplinary diversity and non-commercial incentives around knowledge production and\\nsocial benefit, to provide distinctive guidance on the development and deployment of foundation\\nmodels that is both technically and ethically grounded.\\n1.4 Overview of this report\\nIn March 2021, we created an informal community at Stanford University of students, faculty,\\nand researchers interested in some aspect of foundation models.15From the very beginning, the\\ncommunity included not just AI researchers, but those eager to apply foundation models to their\\ndomain (e.g., healthcare and law), as well as those who were interested in societal concerns\\n(e.g., ethics and economics). As discussions progressed, we noticed that there were many gaps in\\nmutual understanding — how the technology worked, how industry develops foundation models,\\nhow to think about the ethical concerns, etc., and existing literature only covered bits and pieces.\\nWe wanted to therefore provide a fuller picture of foundation models, identify opportunities and\\nrisks, and establish a constructive vision for the future responsible development of foundation\\nmodels.\\nThe writing of this report was an experiment: we had over 100 people from different backgrounds\\ncome together to write a single report covering a wide range of aspects of foundation models. A\\nlarge part of this report is a survey of existing work, but through many discussions, we have unified\\nit in one report to highlight all the interdisciplinary connections.\\nStructure. The report is divided into 26 sections, each discussing one aspect of foundation models.\\nThe sections are grouped into four parts: capabilities (§2: capabilities ), applications (§3: ap-\\nplications ), technology (§4: technology ), and society (§5: society ), although there are many\\nconnections across sections. These connections highlight an integrated approach in which the\\ntechnologies and capabilities are developed in a way that is sensitive to real societal concerns, while\\nbeing inspired by and grounded out in applications.\\nWhile we have sought to capture most of the important topics surrounding foundation models,\\nthis report will inevitably be incomplete, especially as the field evolves quickly. For example, many\\napplications (e.g., natural sciences, music, finance, agriculture) are not included, though they are as\\nlikely to be affected as the applications we have chosen to discuss. It would also be interesting to\\n15This community led to the founding of the Center for Research on Foundation Models (CRFM) , a new interdisciplinary\\ninitiative at the Stanford Institute for Human-Centered AI (HAI).', metadata={'source': 'foundation-model.pdf', 'page': 11})]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['answer']"
      ],
      "metadata": {
        "id": "cM3DcAF4Uqvh",
        "outputId": "66df7732-c107-4bbc-9f26-27060b2f28d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'기초 모델의 제안은 다양한 하위 작업에 적용할 수 있는 광범위한 데이터로 훈련된 모델을 개발하는 것입니다. 이러한 모델은 BERT, DALL-E, GPT-3 등으로 알려진 모델들을 포함하며, 언어, 비전, 로봇 조작, 추론, 인간 상호작용 등 다양한 능력을 갖추고 있습니다. 이 보고서는 기초 모델의 기회와 위험에 대해 상세히 설명하고 있으며, 모델의 능력, 기술 원칙, 응용 분야, 사회적 영향 등을 다루고 있습니다. 또한, 기초 모델의 결함이 하위 작업에 적용된 모든 모델에 상속된다는 주의가 필요하다고 언급하고 있습니다. 이러한 질문들에 대한 명확한 이해와 연구를 위해 깊은 학문적 협력이 필요하다고 강조하고 있습니다. ('"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['source_documents']"
      ],
      "metadata": {
        "id": "TxNF1I2pUzIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in result['source_documents']:\n",
        "    print('내용 : ' + doc.page_content[0:100].replace('\\n', ' '))\n",
        "    print('파일 : ' + doc.metadata['source'])\n",
        "    print('페이지 : ' + str(doc.metadata['page']))"
      ],
      "metadata": {
        "id": "sSOqIBzXU6f_",
        "outputId": "1bae83af-1bee-4b0a-b725-99739da33d51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "내용 : On the Opportunities and Risks of Foundation Models Rishi Bommasani* Drew A. Hudson Ehsan Adeli Russ\n",
            "파일 : foundation-model.pdf\n",
            "페이지 : 0\n",
            "내용 : 12 Center for Research on Foundation Models (CRFM) Another complementary approach is to rely on volu\n",
            "파일 : foundation-model.pdf\n",
            "페이지 : 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio # 그라디오 라이브러리를 설치합니다."
      ],
      "metadata": {
        "id": "VHPK_8ZWHCRb",
        "outputId": "1e98e948-2118-4867-b279-ac21932ec7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.35.2)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.99.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.2.7)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.9)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.7->gradio) (4.6.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.5.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (0.17.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.1.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.16)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "oiK40JG5hKky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def respond(message, chat_history):  # 채팅봇의 응답을 처리하는 함수를 정의합니다.\n",
        "\n",
        "    result = chain(message)\n",
        "\n",
        "    bot_message = result['answer']\n",
        "\n",
        "    for i, doc in enumerate(result['source_documents']):\n",
        "        bot_message += '[' + str(i+1) + '] ' + doc.metadata['source'] + '(' + str(doc.metadata['page']) + ') '\n",
        "\n",
        "    chat_history.append((message, bot_message))  # 채팅 기록에 사용자의 메시지와 봇의 응답을 추가합니다.\n",
        "\n",
        "    return \"\", chat_history  # 수정된 채팅 기록을 반환합니다.\n",
        "\n",
        "with gr.Blocks() as demo:  # gr.Blocks()를 사용하여 인터페이스를 생성합니다.\n",
        "    chatbot = gr.Chatbot(label=\"채팅창\")  # '채팅창'이라는 레이블을 가진 채팅봇 컴포넌트를 생성합니다.\n",
        "    msg = gr.Textbox(label=\"입력\")  # '입력'이라는 레이블을 가진 텍스트박스를 생성합니다.\n",
        "    clear = gr.Button(\"초기화\")  # '초기화'라는 레이블을 가진 버튼을 생성합니다.\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])  # 텍스트박스에 메시지를 입력하고 제출하면 respond 함수가 호출되도록 합니다.\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)  # '초기화' 버튼을 클릭하면 채팅 기록을 초기화합니다.\n",
        "\n",
        "demo.launch(debug=True)  # 인터페이스를 실행합니다. 실행하면 사용자는 '입력' 텍스트박스에 메시지를 작성하고 제출할 수 있으며, '초기화' 버튼을 통해 채팅 기록을 초기화 할 수 있습니다."
      ],
      "metadata": {
        "id": "Yl_SXA37i4p5",
        "outputId": "67041596-f654-4903-931d-f506288f3048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l8LrpDnskG7y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}